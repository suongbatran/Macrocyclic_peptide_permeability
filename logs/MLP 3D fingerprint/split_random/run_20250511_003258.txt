Starting hyperparameter search at Sun 11 May 2025 12:32:58 AM EDT
Logging to: /home/suongtr/Mol4Eng/Mol4Eng_macrocyclic_peptide_permeability/logs/MLP_e3fp/split_random/run_20250511_003258.txt
➤ Preprocessing: bits=1024, level=3, radius=1.0
Training: hidden=64, lr=1e-3, agg=mean
===> New best model found! Val score: 0.009117539698220389
Training: hidden=64, lr=1e-3, agg=sum
Training: hidden=64, lr=1e-3, agg=softmax
Training: hidden=64, lr=1e-3, agg=softmin
Training: hidden=64, lr=1e-4, agg=mean
Training: hidden=64, lr=1e-4, agg=sum
Training: hidden=64, lr=1e-4, agg=softmax
Training: hidden=64, lr=1e-4, agg=softmin
Training: hidden=128, lr=1e-3, agg=mean
===> New best model found! Val score: 0.009105282824170592
Training: hidden=128, lr=1e-3, agg=sum
Training: hidden=128, lr=1e-3, agg=softmax
Training: hidden=128, lr=1e-3, agg=softmin
Training: hidden=128, lr=1e-4, agg=mean
Training: hidden=128, lr=1e-4, agg=sum
Training: hidden=128, lr=1e-4, agg=softmax
Training: hidden=128, lr=1e-4, agg=softmin
Training: hidden=256, lr=1e-3, agg=mean
===> New best model found! Val score: 0.009075396369294752
Training: hidden=256, lr=1e-3, agg=sum
Training: hidden=256, lr=1e-3, agg=softmax
Training: hidden=256, lr=1e-3, agg=softmin
Training: hidden=256, lr=1e-4, agg=mean
Training: hidden=256, lr=1e-4, agg=sum
Training: hidden=256, lr=1e-4, agg=softmax
Training: hidden=256, lr=1e-4, agg=softmin
➤ Preprocessing: bits=1024, level=3, radius=2.0
Training: hidden=64, lr=1e-3, agg=mean
===> New best model found! Val score: 0.00590546552094771
Training: hidden=64, lr=1e-3, agg=sum
===> New best model found! Val score: 0.005809969381456395
Training: hidden=64, lr=1e-3, agg=softmax
Training: hidden=64, lr=1e-3, agg=softmin
Training: hidden=64, lr=1e-4, agg=mean
Training: hidden=64, lr=1e-4, agg=sum
Training: hidden=64, lr=1e-4, agg=softmax
Training: hidden=64, lr=1e-4, agg=softmin
Training: hidden=128, lr=1e-3, agg=mean
Training: hidden=128, lr=1e-3, agg=sum
Training: hidden=128, lr=1e-3, agg=softmax
Training: hidden=128, lr=1e-3, agg=softmin
Training: hidden=128, lr=1e-4, agg=mean
Training: hidden=128, lr=1e-4, agg=sum
Training: hidden=128, lr=1e-4, agg=softmax
Training: hidden=128, lr=1e-4, agg=softmin
Training: hidden=256, lr=1e-3, agg=mean
Training: hidden=256, lr=1e-3, agg=sum
===> New best model found! Val score: 0.005524488381628729
Training: hidden=256, lr=1e-3, agg=softmax
Training: hidden=256, lr=1e-3, agg=softmin
Training: hidden=256, lr=1e-4, agg=mean
Training: hidden=256, lr=1e-4, agg=sum
Training: hidden=256, lr=1e-4, agg=softmax
Training: hidden=256, lr=1e-4, agg=softmin
➤ Preprocessing: bits=1024, level=3, radius=3.0
Training: hidden=64, lr=1e-3, agg=mean
Training: hidden=64, lr=1e-3, agg=sum
===> New best model found! Val score: 0.00468425948566951
Training: hidden=64, lr=1e-3, agg=softmax
Training: hidden=64, lr=1e-3, agg=softmin
Training: hidden=64, lr=1e-4, agg=mean
Training: hidden=64, lr=1e-4, agg=sum
Training: hidden=64, lr=1e-4, agg=softmax
Training: hidden=64, lr=1e-4, agg=softmin
Training: hidden=128, lr=1e-3, agg=mean
Training: hidden=128, lr=1e-3, agg=sum
Training: hidden=128, lr=1e-3, agg=softmax
Training: hidden=128, lr=1e-3, agg=softmin
Training: hidden=128, lr=1e-4, agg=mean
Training: hidden=128, lr=1e-4, agg=sum
Training: hidden=128, lr=1e-4, agg=softmax
Training: hidden=128, lr=1e-4, agg=softmin
Training: hidden=256, lr=1e-3, agg=mean
Training: hidden=256, lr=1e-3, agg=sum
Training: hidden=256, lr=1e-3, agg=softmax
Training: hidden=256, lr=1e-3, agg=softmin
Training: hidden=256, lr=1e-4, agg=mean
Training: hidden=256, lr=1e-4, agg=sum
Training: hidden=256, lr=1e-4, agg=softmax
Training: hidden=256, lr=1e-4, agg=softmin
➤ Preprocessing: bits=1024, level=4, radius=1.0
Training: hidden=64, lr=1e-3, agg=mean
Training: hidden=64, lr=1e-3, agg=sum
Training: hidden=64, lr=1e-3, agg=softmax
Training: hidden=64, lr=1e-3, agg=softmin
Training: hidden=64, lr=1e-4, agg=mean
Training: hidden=64, lr=1e-4, agg=sum
Training: hidden=64, lr=1e-4, agg=softmax
Training: hidden=64, lr=1e-4, agg=softmin
Training: hidden=128, lr=1e-3, agg=mean
Training: hidden=128, lr=1e-3, agg=sum
Training: hidden=128, lr=1e-3, agg=softmax
Training: hidden=128, lr=1e-3, agg=softmin
Training: hidden=128, lr=1e-4, agg=mean
Training: hidden=128, lr=1e-4, agg=sum
Training: hidden=128, lr=1e-4, agg=softmax
Training: hidden=128, lr=1e-4, agg=softmin
Training: hidden=256, lr=1e-3, agg=mean
Training: hidden=256, lr=1e-3, agg=sum
Training: hidden=256, lr=1e-3, agg=softmax
Training: hidden=256, lr=1e-3, agg=softmin
Training: hidden=256, lr=1e-4, agg=mean
Training: hidden=256, lr=1e-4, agg=sum
Training: hidden=256, lr=1e-4, agg=softmax
Training: hidden=256, lr=1e-4, agg=softmin
➤ Preprocessing: bits=1024, level=4, radius=2.0
Training: hidden=64, lr=1e-3, agg=mean
Training: hidden=64, lr=1e-3, agg=sum
Training: hidden=64, lr=1e-3, agg=softmax
Training: hidden=64, lr=1e-3, agg=softmin
Training: hidden=64, lr=1e-4, agg=mean
Training: hidden=64, lr=1e-4, agg=sum
Training: hidden=64, lr=1e-4, agg=softmax
Training: hidden=64, lr=1e-4, agg=softmin
Training: hidden=128, lr=1e-3, agg=mean
Training: hidden=128, lr=1e-3, agg=sum
Training: hidden=128, lr=1e-3, agg=softmax
Training: hidden=128, lr=1e-3, agg=softmin
Training: hidden=128, lr=1e-4, agg=mean
Training: hidden=128, lr=1e-4, agg=sum
Training: hidden=128, lr=1e-4, agg=softmax
Training: hidden=128, lr=1e-4, agg=softmin
Training: hidden=256, lr=1e-3, agg=mean
Training: hidden=256, lr=1e-3, agg=sum
Training: hidden=256, lr=1e-3, agg=softmax
Training: hidden=256, lr=1e-3, agg=softmin
Training: hidden=256, lr=1e-4, agg=mean
Training: hidden=256, lr=1e-4, agg=sum
Training: hidden=256, lr=1e-4, agg=softmax
Training: hidden=256, lr=1e-4, agg=softmin
➤ Preprocessing: bits=1024, level=4, radius=3.0
Training: hidden=64, lr=1e-3, agg=mean
Training: hidden=64, lr=1e-3, agg=sum
Training: hidden=64, lr=1e-3, agg=softmax
Training: hidden=64, lr=1e-3, agg=softmin
Training: hidden=64, lr=1e-4, agg=mean
Training: hidden=64, lr=1e-4, agg=sum
Training: hidden=64, lr=1e-4, agg=softmax
Training: hidden=64, lr=1e-4, agg=softmin
Training: hidden=128, lr=1e-3, agg=mean
Training: hidden=128, lr=1e-3, agg=sum
Training: hidden=128, lr=1e-3, agg=softmax
Training: hidden=128, lr=1e-3, agg=softmin
Training: hidden=128, lr=1e-4, agg=mean
Training: hidden=128, lr=1e-4, agg=sum
Training: hidden=128, lr=1e-4, agg=softmax
Training: hidden=128, lr=1e-4, agg=softmin
Training: hidden=256, lr=1e-3, agg=mean
Training: hidden=256, lr=1e-3, agg=sum
===> New best model found! Val score: 0.004681791156143083
Training: hidden=256, lr=1e-3, agg=softmax
Training: hidden=256, lr=1e-3, agg=softmin
Training: hidden=256, lr=1e-4, agg=mean
Training: hidden=256, lr=1e-4, agg=sum
Training: hidden=256, lr=1e-4, agg=softmax
Training: hidden=256, lr=1e-4, agg=softmin
➤ Preprocessing: bits=1024, level=5, radius=1.0
Training: hidden=64, lr=1e-3, agg=mean
Training: hidden=64, lr=1e-3, agg=sum
Training: hidden=64, lr=1e-3, agg=softmax
Training: hidden=64, lr=1e-3, agg=softmin
Training: hidden=64, lr=1e-4, agg=mean
Training: hidden=64, lr=1e-4, agg=sum
Training: hidden=64, lr=1e-4, agg=softmax
Training: hidden=64, lr=1e-4, agg=softmin
Training: hidden=128, lr=1e-3, agg=mean
Training: hidden=128, lr=1e-3, agg=sum
Training: hidden=128, lr=1e-3, agg=softmax
Training: hidden=128, lr=1e-3, agg=softmin
Training: hidden=128, lr=1e-4, agg=mean
Training: hidden=128, lr=1e-4, agg=sum
Training: hidden=128, lr=1e-4, agg=softmax
Training: hidden=128, lr=1e-4, agg=softmin
Training: hidden=256, lr=1e-3, agg=mean
Training: hidden=256, lr=1e-3, agg=sum
Training: hidden=256, lr=1e-3, agg=softmax
Training: hidden=256, lr=1e-3, agg=softmin
Training: hidden=256, lr=1e-4, agg=mean
Training: hidden=256, lr=1e-4, agg=sum
Training: hidden=256, lr=1e-4, agg=softmax
Training: hidden=256, lr=1e-4, agg=softmin
➤ Preprocessing: bits=1024, level=5, radius=2.0
Training: hidden=64, lr=1e-3, agg=mean
Training: hidden=64, lr=1e-3, agg=sum
Training: hidden=64, lr=1e-3, agg=softmax
Training: hidden=64, lr=1e-3, agg=softmin
Training: hidden=64, lr=1e-4, agg=mean
Training: hidden=64, lr=1e-4, agg=sum
Training: hidden=64, lr=1e-4, agg=softmax
Training: hidden=64, lr=1e-4, agg=softmin
Training: hidden=128, lr=1e-3, agg=mean
Training: hidden=128, lr=1e-3, agg=sum
Training: hidden=128, lr=1e-3, agg=softmax
Training: hidden=128, lr=1e-3, agg=softmin
Training: hidden=128, lr=1e-4, agg=mean
Training: hidden=128, lr=1e-4, agg=sum
Training: hidden=128, lr=1e-4, agg=softmax
Training: hidden=128, lr=1e-4, agg=softmin
Training: hidden=256, lr=1e-3, agg=mean
Training: hidden=256, lr=1e-3, agg=sum
Training: hidden=256, lr=1e-3, agg=softmax
Training: hidden=256, lr=1e-3, agg=softmin
Training: hidden=256, lr=1e-4, agg=mean
Training: hidden=256, lr=1e-4, agg=sum
Training: hidden=256, lr=1e-4, agg=softmax
Training: hidden=256, lr=1e-4, agg=softmin
➤ Preprocessing: bits=1024, level=5, radius=3.0
Training: hidden=64, lr=1e-3, agg=mean
Training: hidden=64, lr=1e-3, agg=sum
Training: hidden=64, lr=1e-3, agg=softmax
Training: hidden=64, lr=1e-3, agg=softmin
Training: hidden=64, lr=1e-4, agg=mean
Training: hidden=64, lr=1e-4, agg=sum
Training: hidden=64, lr=1e-4, agg=softmax
Training: hidden=64, lr=1e-4, agg=softmin
Training: hidden=128, lr=1e-3, agg=mean
Training: hidden=128, lr=1e-3, agg=sum
Training: hidden=128, lr=1e-3, agg=softmax
Training: hidden=128, lr=1e-3, agg=softmin
Training: hidden=128, lr=1e-4, agg=mean
